{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The ETL part of the analysis can be found here:\n",
    "https://github.com/vosilov/Data-Science-Portfolio/blob/master/AirBnB-Kaggle-Competition/airbnb_kaggle_ETL.ipynb\n",
    "The data is saved in an hdf5 file, which we will now load and start the predictive analysis. Let's first do all the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data from the hdf5 file saved earlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF = pd.read_hdf('airbnb_ready.h5', 'train_df')\n",
    "testDF = pd.read_hdf('airbnb_ready.h5', 'test_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to, first, use `LabelEncoder` to label the categories of the output variable __`country_destination`__. For computational efficiency we can convert the data into sparse matrices. According to the sklearn documentation:\n",
    "> _As a rule of thumb you can consider that if the sparsity ratio is greater than 90% you can probably benefit from sparse formats._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sparsity ratio: 0.9332431644005321\n"
     ]
    }
   ],
   "source": [
    "# Check sparsity:\n",
    "def sparsity_ratio(X):\n",
    "    return 1.0 - np.count_nonzero(X) / float(X.shape[0] * X.shape[1])\n",
    "print(\"input sparsity ratio:\", sparsity_ratio(trainDF))\n",
    "\n",
    "sparse_testDF = csc_matrix(testDF.values)\n",
    "X = csc_matrix(trainDF.iloc[:, 1:].values)\n",
    "y = trainDF.iloc[:, 0]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, after converting the data to sparse matrices, we split the training data into train/test(validation) sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF = 0\n",
    "testDF = 0\n",
    "X = 0\n",
    "y = 0\n",
    "# to save some memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first fit a Logistic Regression and take a look at the 5x3 nested cross-validation score. Nested cross validation is recommended to use when selecting among competing models and simultaneously tuning their parameters in order to avoid overfitting the training data. The score we get out of a nested cross validation is a reliable estimate of how a tuned model would perform when given an unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated accuracy: 0.696 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "pipe_lr = make_pipeline(StandardScaler(with_mean=0), logreg)\n",
    "\n",
    "choiceofc = [10 ** c for c in np.arange(-4, 3)]\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "              'logisticregression__C': choiceofc}\n",
    "\n",
    "logreg_gs = GridSearchCV(estimator=pipe_lr, param_grid=param_grid,\n",
    "                         scoring='accuracy', cv=3, n_jobs=-1)\n",
    "logreg_scores = cross_val_score(logreg_gs, X_train, y_train,\n",
    "                                scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "print('Cross validated accuracy: %.3f +/- %.3f' %\n",
    "      (np.mean(logreg_scores), np.std(logreg_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of a tuned Logistic Regression would be almost 70% when given new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try a Random Forest classifier and output the mean 5x3 nested cross-validation scores, along with their standard deviation. Typically, the higher the number of trees (`n_estimators` parameter) in the forest the better the performance at the cost of increased number of computations. Here, I choose `n_estimators` = 1500. The parameter that we can think of tuning using a grid search is the maximum number of features in each tree, `max_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x3 Nested cross-validation Random Forest accuracy: 0.703 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1500, oob_score=1, n_jobs=-1,\n",
    "                                warm_start=1, verbose=1, random_state=1)\n",
    "\n",
    "param_grid = {'max_features': ['sqrt', 'log2', 0.1]}\n",
    "forest_gs = GridSearchCV(estimator=forest, param_grid=param_grid,\n",
    "                         scoring='accuracy', cv=3, n_jobs=3)\n",
    "forest_scores = cross_val_score(forest_gs, X_train, y_train,\n",
    "                                scoring='accuracy', cv=5, n_jobs=5)\n",
    "\n",
    "print('5x3 Nested cross-validation Random Forest accuracy: %.3f +/- %.3f' %\n",
    "      (np.mean(forest_scores), np.std(forest_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model with an estimated accuracy of 0.703 performs a bit better than the Logistic Regression model we saw earlier with an accuracy of 0.696."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try an AdaBoost classifier, again, with a 5x3 nested cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x5 Nested Cross-validation AdaBoost scores: [ 0.68029111  0.6820452   0.68430858  0.67860772  0.68631936]\n",
      "Accuracy: 0.682 (+/- 0.006)\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                              random_state=1)\n",
    "\n",
    "param_grid = {'n_estimators': [100, 400, 800],\n",
    "              'learning_rate': [0.001, 0.01, 0.1, 1, 10]}\n",
    "adaboost_gs = GridSearchCV(adaboost, param_grid, scoring='accuracy', cv=5,\n",
    "                           n_jobs=-1)\n",
    "adaboost_scores = cross_val_score(adaboost_gs, X_train, y_train,\n",
    "                                  scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "print(\"5x5 Nested cross-validation AdaBoost accuracy: {}\".format(adaboost_scores))\n",
    "print(\"Accuracy: {0.3f} (+/- {0.3f})\".format(adaboost_scores.mean(),\n",
    "                                             adaboost_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs a bit worse than the previous two. Typically, decision stumps (decision tree model with max depth of 1) are used as base estimators in the AdaBoost ensemble. Next, we do just that, to compare with the AdaBoost performance above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x3 Nested cross-validation AdaBoost accuracy: [ 0.68460692  0.6854313   0.68744178  0.68148713  0.6884371 ]\n",
      "Accuracy: 0.685 (+/- 0.005)\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "adaboost = AdaBoostClassifier(base_estimator=tree, random_state=1)\n",
    "\n",
    "param_grid = {'n_estimators': [100, 400, 800],\n",
    "              'learning_rate': [0.001, 0.01, 0.1, 1, 10]}\n",
    "adaboost_gs_2 = GridSearchCV(adaboost, param_grid, scoring='accuracy',\n",
    "                             cv=3, n_jobs=-1)\n",
    "adaboost_scores_2 = cross_val_score(adaboost_gs_2, X_train, y_train,\n",
    "                                    scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "print(\"5x3 Nested cross-validation AdaBoost accuracy: {}\".format(adaboost_scores_2))\n",
    "print(\"Accuracy: {0.3f} (+/- {0.3f})\".format(adaboost_scores_2.mean(),\n",
    "                                             adaboost_scores_2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much difference and the Random Forest model remains the best performer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the three models, Random Forest performed best. So, now we can tune and train it to see how it performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_features': 0.1}\n",
      "Best cross-validation score: 0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 1500 out of 1500 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.704\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1500, oob_score=1, n_jobs=6,\n",
    "                                warm_start=1, verbose=2, random_state=1)\n",
    "\n",
    "param_grid = {'max_features': ['sqrt', 'log2', 0.1]}\n",
    "forest_gs = GridSearchCV(estimator=forest, param_grid=param_grid,\n",
    "                         scoring='accuracy', cv=3, n_jobs=3)\n",
    "forest_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(forest_gs.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(forest_gs.best_score_))\n",
    "print(\"Test set accuracy: {:.3f}\".format(forest_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best cross-validation accuracy is 0.701 and the best value for the `max_features` parameter is 0.1 (i.e. a maximum of 10% of the features is used for each of the trees in the ensemble).\n",
    "The test set accuracy is almost the same as the cross-validated score. It is even slightly higher.\n",
    "\n",
    "If we just predict `NDF`, which is the most frequently observed class in the output variable, we will get an accuracy of 0.611 on the test set, as we can see below. So, our model is better than just simply guessing no booking was done for all the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels: ['NDF']\n",
      "Dummy test score: 0.611\n"
     ]
    }
   ],
   "source": [
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = le.inverse_transform(dummy_majority.predict(X_test))\n",
    "\n",
    "print(\"Unique predicted labels: {}\".format(np.unique(pred_most_frequent)))\n",
    "print(\"Dummy test score: {:.3f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The official scoring method of the kaggle competition was Normalized Discounted Cumulative Gain (NDCG). Below we have simple functions to calculate an NDCG score for the maximum number of submission allowed, k=5. The predictions have to be class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "    y_true : array, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    Returns: score (float)\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    "    recommendation system based on the graded relevance of the recommended\n",
    "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    "    ranking of the entities.\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes]\n",
    "        Predicted probabilities.\n",
    "    k : int\n",
    "        Rank.\n",
    "    Returns: score (float)\n",
    "    Example\n",
    "    -------\n",
    "    >>> ground_truth = [1, 0, 2]\n",
    "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    1.0\n",
    "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    0.6666666666\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    # get first array element of predictions array to correct calculate ground_truth len\n",
    "    lb.fit(range(len(predictions[0]) + 1))\n",
    "    T = lb.transform(ground_truth)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        \n",
    "        # HACK: Should not be needed, but in case nothing was relevant\n",
    "        if best <= 0:\n",
    "            score = 0.0\n",
    "        else:\n",
    "            score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a scorer that we can easily use with sklearn during grid searches instead of accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, let's see how our Random Forest model performed when evaluated using the NDCG score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set NDCG score: 0.853758\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_gs.predict_proba(X_test)\n",
    "print(\"Test set NDCG score: {:.6f}\".format(ndcg_score(ground_truth=y_test,\n",
    "                                                      predictions=y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701347964506\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        26\n",
      "          1       0.00      0.00      0.00        84\n",
      "          2       0.00      0.00      0.00        48\n",
      "          3       0.00      0.00      0.00       130\n",
      "          4       0.50      0.00      0.01       283\n",
      "          5       0.00      0.00      0.00       142\n",
      "          6       0.00      0.00      0.00       186\n",
      "          7       0.75      0.90      0.82      9019\n",
      "          8       0.00      0.00      0.00        48\n",
      "          9       0.00      0.00      0.00        12\n",
      "         10       0.56      0.55      0.56      4031\n",
      "         11       0.00      0.00      0.00       754\n",
      "\n",
      "avg / total       0.62      0.70      0.65     14763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rustam\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "logreg_gs.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, logreg_gs.predict(X_test)\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a stacked ensemble, where we tune and fit the three models shown above (Logistic Regression, Random Forest, AdaBoost) to generate predictions. These predictions, then, are used as meta-features for the meta-classifier to produce a final prediction, which should be better than any of their individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.694\n",
      " Best model parameters: \n",
      "{'meta-logisticregression__C': 1.0, 'adaboostclassifier__n_estimators': 100, 'randomforestclassifier__n_estimators': 200, 'logisticregression__C': 0.01, 'adaboostclassifier__learning_rate': 1, 'logisticregression__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=1, n_jobs=-1)\n",
    "forest = RandomForestClassifier(oob_score=1, n_jobs=-1, random_state=1)\n",
    "adaboost = AdaBoostClassifier(random_state=1)\n",
    "stacking_clf = StackingClassifier(classifiers=[logreg, forest, adaboost],\n",
    "                                  meta_classifier=logreg,\n",
    "                                  use_probas=1)\n",
    "\n",
    "params = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "          'logisticregression__C': np.logspace(-3, 2, 6),\n",
    "          'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "          'adaboostclassifier__n_estimators': [50, 100, 200],\n",
    "          'adaboostclassifier__learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "          'meta-logisticregression__C': np.logspace(-3, 2, 6)}\n",
    "stacked_grid = GridSearchCV(estimator=stacking_clf, param_grid=params,\n",
    "                            cv=3, refit=True, verbose=2, n_jobs=-1)\n",
    "stacked_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\\n Best model parameters: \\n%r\" %\n",
    "      (stacked_grid.best_score_, stacked_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search had a total of 2592 x 3 models to fit and evaluate. It took almost 5 days (118 hours) to finish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69965454176\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, stacked_grid.predict(X_test)\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'use_probas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1961cdcb063b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m params_2 = {'randomforestclassifier__n_estimators': [200, 500, 1000, 1500],\n\u001b[1;32m      9\u001b[0m             'randomforestclassifier__max_features': ['sqrt', 'log2']}\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstacked_grid_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacking_clf_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_probas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mstacked_grid_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'use_probas'"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.01, penalty='l1', random_state=1, n_jobs=-1)\n",
    "forest = RandomForestClassifier(oob_score=1, n_jobs=-1, random_state=1,\n",
    "                                warm_start=1)\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=1, random_state=1)\n",
    "lr = LogisticRegression(C=1, random_state=1, n_jobs=-1)\n",
    "stacking_clf_2 = StackingClassifier(classifiers=[logreg, forest, adaboost],\n",
    "                                    meta_classifier=lr,\n",
    "                                    use_probas=1)\n",
    "\n",
    "params_2 = {'randomforestclassifier__n_estimators': [400, 800, 1200],\n",
    "            'randomforestclassifier__max_features': ['sqrt', 'log2', 0.1]}\n",
    "stacked_grid_2 = GridSearchCV(estimator=stacking_clf_2, param_grid=params_2,\n",
    "                              cv=3, refit=True, verbose=2, n_jobs=-1)\n",
    "stacked_grid_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, stacked_grid_2.predict(X_test)\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have almost 800 features, the parameter tuning and model fitting takes a long time. Let's try dimensionality reduction using PCA so we can have fewer features and save some time. This allows us to compress the data while maintaining most of the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAAHLCAYAAAAz2/IoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt+tZu+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1892e7dabe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=None, random_state=1)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), pca)\n",
    "pipe.fit(X_train)\n",
    "expl_var_ratio = pipe.named_steps[\"pca\"].explained_variance_ratio_\n",
    "\n",
    "plt.figure(1, figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.bar(range(1, 401), expl_var_ratio[:400], alpha=0.5, align='center',\n",
    "        label='individual explained variance')\n",
    "plt.step(range(1,401), np.cumsum(expl_var_ratio)[:400], where='mid',\n",
    "         label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94107606282001721"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(expl_var_ratio[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, the first 400 principal components are able to explain about 94 percent of the variance in the data. Let's now fit a logistic regression with PCA preprocessing with these 400 principal components:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated accuracy of Logistic Regression after PCA and StandardScaler preprocessing: \n",
      " 0.680 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "pca = PCA(n_components=300, random_state=1)\n",
    "pipe = make_pipeline(StandardScaler(), pca, StandardScaler(), logreg)\n",
    "\n",
    "Cs = np.logspace(-3, 2, 6)\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "              'logisticregression__C': Cs}\n",
    "\n",
    "pca_logreg = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, n_jobs=4)\n",
    "pca_logreg_scores = cross_val_score(pca_logreg, X_train, y_train,\n",
    "                                    scoring='accuracy', cv=3, n_jobs=4)\n",
    "\n",
    "print('Cross validated accuracy of Logistic Regression after PCA and StandardScaler preprocessing: \\n %.3f +/- %.3f' %\n",
    "      (np.mean(pca_logreg_scores), np.std(pca_logreg_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 principal components - accuracy: 0.667 +/- 0.002:\n",
    "start - 18:29\n",
    "finish - 19:08\n",
    "39 minutes\n",
    "\n",
    "300 principal components - accuracy: 0.680 +/- 0.003:\n",
    "start - 19:13\n",
    "finish - 06:50\n",
    "11 hours 40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated accuracy of Random Forest after PCA and StandardScaler preprocessing: \n",
      " 0.675 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000, oob_score=1, n_jobs=4,\n",
    "                                random_state=1)\n",
    "pca = PCA(n_components=300, random_state=1)\n",
    "\n",
    "param_grid = {'randomforestclassifier__max_features': ['log2', 'sqrt']}\n",
    "pipeforest = make_pipeline(StandardScaler(), pca, forest)\n",
    "pca_forest = GridSearchCV(estimator=pipeforest, param_grid=param_grid,\n",
    "                          cv=3, n_jobs=6)\n",
    "pca_forest_scores = cross_val_score(pca_forest, X_train, y_train,\n",
    "                                    scoring='accuracy', cv=3, n_jobs=6)\n",
    "\n",
    "print('Cross validated accuracy of Random Forest after PCA and StandardScaler preprocessing: \\n %.3f +/- %.3f' %\n",
    "      (np.mean(pca_forest_scores), np.std(pca_forest_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300 principal components - accuracy: 0.675 +/- 0.002:\n",
    "start - 08:02\n",
    "finish - 08:42\n",
    "40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.69814674  0.69939897  0.69794225  0.69486789  0.69767048]\n",
      "Accuracy: 0.698 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(forest, X_train, y_train, scoring='accuracy', cv=5,\n",
    "                         n_jobs=-1)\n",
    "print(\"Cross-validation Random Forest accuracy: {}\".format(scores))\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An all-in-one grid search to select the best model between a Logistic Regression and a Random Forest with its respective best parameters. For the Logistic Regression model we also include an option of preprocessing with a StandardScaler, which will demean the observations and divide by their standard deviation. (will take quite a while to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rustam\\Anaconda3\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Rustam\\Anaconda3\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Rustam\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 429, in _handle_results\n",
      "    task = get()\n",
      "  File \"C:\\Users\\Rustam\\Anaconda3\\lib\\multiprocessing\\connection.py\", line 251, in recv\n",
      "    return ForkingPickler.loads(buf.getbuffer())\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 654, in sklearn.tree._tree.Tree.__setstate__ (sklearn\\tree\\_tree.c:8453)\n",
      "MemoryError: resizing tree to 27041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "forest = RandomForestClassifier(oob_score=1, n_jobs=-1, random_state=0)\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', logreg)])\n",
    "\n",
    "param_grid = [\n",
    "              {'classifier': [logreg],\n",
    "               'preprocessing': [StandardScaler(), None],\n",
    "               'classifier__penalty': ['l1', 'l2'],\n",
    "               'classifier__C': [0.001, 0.01, 0.1, 1, 10]},\n",
    "              {'classifier': [forest],'preprocessing': [None],\n",
    "               'classifier__n_estimators': [100, 250, 500],\n",
    "               'classifier__max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "all_in_one_grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "all_in_one_grid.fit(X_train, y_train)\n",
    "print(\"Best parameters:\\n{}\\n\".format(all_in_one_grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(all_in_one_grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(all_in_one_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
